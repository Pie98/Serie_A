{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cookie popup not found or encountered an error: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF7AD1C82B2+55298]\n",
      "\t(No symbol) [0x00007FF7AD135E02]\n",
      "\t(No symbol) [0x00007FF7ACFF05AB]\n",
      "\t(No symbol) [0x00007FF7AD03175C]\n",
      "\t(No symbol) [0x00007FF7AD0318DC]\n",
      "\t(No symbol) [0x00007FF7AD06CBC7]\n",
      "\t(No symbol) [0x00007FF7AD0520EF]\n",
      "\t(No symbol) [0x00007FF7AD06AAA4]\n",
      "\t(No symbol) [0x00007FF7AD051E83]\n",
      "\t(No symbol) [0x00007FF7AD02670A]\n",
      "\t(No symbol) [0x00007FF7AD027964]\n",
      "\tGetHandleVerifier [0x00007FF7AD540AAB+3694587]\n",
      "\tGetHandleVerifier [0x00007FF7AD59728E+4048862]\n",
      "\tGetHandleVerifier [0x00007FF7AD58F173+4015811]\n",
      "\tGetHandleVerifier [0x00007FF7AD2647D6+695590]\n",
      "\t(No symbol) [0x00007FF7AD140CE8]\n",
      "\t(No symbol) [0x00007FF7AD13CF34]\n",
      "\t(No symbol) [0x00007FF7AD13D062]\n",
      "\t(No symbol) [0x00007FF7AD12D3A3]\n",
      "\tBaseThreadInitThunk [0x00007FF9F64E257D+29]\n",
      "\tRtlUserThreadStart [0x00007FF9F75AAA58+40]\n",
      "\n",
      "HTML saved to last_odds.html\n",
      "['1.67', '2.10', '2.35', '1.55', '1.80', '3.30', '5.00']\n",
      "['2.00', '1.73', '1.92', '1.77', '3.55', '3.30', '2.10']\n",
      "['1.85', '1.87', '1.50', '2.40', '9.00', '5.50', '1.30']\n",
      "['1.80', '1.90', '1.90', '1.80', '5.75', '3.90', '1.60']\n",
      "['1.95', '1.77', '1.70', '2.00', '5.75', '4.25', '1.55']\n",
      "['1.87', '1.85', '1.70', '2.05', '6.75', '4.50', '1.45']\n",
      "['2.35', '1.53', '1.65', '2.10', '3.05', '3.50', '2.25']\n",
      "['1.73', '2.00', '2.40', '1.50', '3.25', '3.00', '2.40']\n",
      "['1.90', '1.80', '1.92', '1.80', '1.75', '3.70', '4.75']\n",
      "['1.77', '1.93', '1.55', '2.30', '9.00', '5.50', '1.30']\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'min_odds.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m start_date_filter \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m15/12\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     27\u001b[0m end_date_filter \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m18/12\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 28\u001b[0m \u001b[43mrefresh_odds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_date_filter\u001b[49m\u001b[43m,\u001b[49m\u001b[43mend_date_filter\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Hp\\Serie_A\\Data_scraping\\odds_scraping.py:122\u001b[0m, in \u001b[0;36mrefresh_odds\u001b[1;34m(start_date_filter, end_date_filter)\u001b[0m\n\u001b[0;32m    120\u001b[0m column_types \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mfloat\u001b[39m}\n\u001b[0;32m    121\u001b[0m last_odds \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlast_odds.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mcolumn_types)\n\u001b[1;32m--> 122\u001b[0m min_odds \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmin_odds.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumn_types\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m last_odds\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m    125\u001b[0m     df_min[col] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mmin\u001b[39m(a, b) \u001b[38;5;28;01mfor\u001b[39;00m a, b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(min_odds[col], last_odds[col])]\n",
      "File \u001b[1;32mc:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'min_odds.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import pandasql as ps\n",
    "import os\n",
    "import re\n",
    "import joblib\n",
    "import random \n",
    "import numpy as np\n",
    "import warnings\n",
    "import tensorflow as tf \n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from preprocess_days_stats import preprocess_match_days\n",
    "from preprocess_time_serie import preprocess_teams, create_time_series_features\n",
    "from preprocess_time_series_features import preprocess_features_time_series, create_fast_preprocessing_ts, preprocess_features_time_series_odds, create_fast_preprocessing_ts_odds\n",
    "from helper_functions_tensorflow import CSVLoggerCallback, CSVLoggerCallbackParams\n",
    "from Data_scraping.odds_scraping import refresh_odds\n",
    "\n",
    "# Ignora tutti i warning temporaneamente\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "today_date = '2023-12-16'\n",
    "start_date_filter = '15/12'\n",
    "end_date_filter = '18/12'\n",
    "refresh_odds(start_date_filter,end_date_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_features_time_series_odds_preds(df_Serie_A, num_features, today_date):\n",
    "\n",
    "    all_features = ['ft_goals','ft_goals_conceded','shots','shots_target', 'fouls_done','corners_obtained', 'yellows', 'reds']\n",
    "    less_features = ['ft_goals','ft_goals_conceded','shots', 'fouls_done','corners_obtained', 'reds']\n",
    "    few_features = ['ft_goals','ft_goals_conceded','shots', 'reds']\n",
    "\n",
    "    Train_df = df_Serie_A.iloc[:10]\n",
    "    Valid_df = df_Serie_A.iloc[:10]\n",
    "    Test_df = df_Serie_A[df_Serie_A['date']==today_date]\n",
    "\n",
    "    Train_labels = Train_df[['ft_result']]\n",
    "    Valid_labels = Valid_df[['ft_result']]\n",
    "    Test_labels = Test_df[['ft_result']]\n",
    "    \n",
    "    Train_odds = Train_df[['home_win_odds','draw_odds','away_win_odds']]\n",
    "    Valid_odds = Valid_df[['home_win_odds','draw_odds','away_win_odds']]\n",
    "    Test_odds = Test_df[['home_win_odds','draw_odds','away_win_odds']]\n",
    "\n",
    "    # preprocess Train dataframe\n",
    "    Train_teams = Train_df[['stagione','hometeam','awayteam']]\n",
    "\n",
    "    if num_features == 'all':\n",
    "        features = all_features\n",
    "        print('utilizzando tutte le features')\n",
    "    elif num_features == 'less':\n",
    "        print('utilizzando meno features')\n",
    "        features = less_features\n",
    "    else:\n",
    "        print('utilizzando poche features')\n",
    "        features=few_features\n",
    "\n",
    "    Train_dict_features={}\n",
    "\n",
    "    for feature in features:\n",
    "        Train_dict_features[feature] = pd.DataFrame({})\n",
    "        for colonna in Train_df.columns:\n",
    "            pattern = re.compile(rf'^home_{feature}_\\d+$')\n",
    "            if pattern.match(colonna):\n",
    "                Train_dict_features[feature][colonna]=Train_df[colonna]\n",
    "        for colonna in Train_df.columns:\n",
    "            pattern = re.compile(rf'^away_{feature}_\\d+$')\n",
    "            if pattern.match(colonna):\n",
    "                Train_dict_features[feature][colonna]=Train_df[colonna]\n",
    "\n",
    "    #preprocess valid dataframe\n",
    "    Valid_teams = Valid_df[['stagione','hometeam','awayteam']]\n",
    "\n",
    "\n",
    "    if num_features == 'all':\n",
    "        features = all_features\n",
    "        print('utilizzando tutte le features')\n",
    "    elif num_features == 'less':\n",
    "        print('utilizzando meno features')\n",
    "        features = less_features\n",
    "    else:\n",
    "        print('utilizzando poche features')\n",
    "        features=few_features\n",
    "\n",
    "    Valid_dict_features={}\n",
    "\n",
    "    for feature in features:\n",
    "        Valid_dict_features[feature] = pd.DataFrame({})\n",
    "        for colonna in Valid_df.columns:\n",
    "            pattern = re.compile(rf'^home_{feature}_\\d+$')\n",
    "            if pattern.match(colonna):\n",
    "                Valid_dict_features[feature][colonna]=Valid_df[colonna]\n",
    "        for colonna in Valid_df.columns:\n",
    "            pattern = re.compile(rf'^away_{feature}_\\d+$')\n",
    "            if pattern.match(colonna):\n",
    "                Valid_dict_features[feature][colonna]=Valid_df[colonna]\n",
    "\n",
    "    # preprocess test dataframe\n",
    "    Test_teams = Test_df[['stagione','hometeam','awayteam']]\n",
    "\n",
    "    if num_features == 'all':\n",
    "        features = all_features\n",
    "        print('utilizzando tutte le features')\n",
    "    elif num_features == 'less':\n",
    "        print('utilizzando meno features')\n",
    "        features = less_features\n",
    "    else:\n",
    "        print('utilizzando poche features')\n",
    "        features=few_features\n",
    "\n",
    "    Test_dict_features={}\n",
    "\n",
    "    for feature in features:\n",
    "        Test_dict_features[feature] = pd.DataFrame({})\n",
    "        for colonna in Test_df.columns:\n",
    "            pattern = re.compile(rf'^home_{feature}_\\d+$')\n",
    "            if pattern.match(colonna):\n",
    "                Test_dict_features[feature][colonna]=Test_df[colonna]\n",
    "        for colonna in Test_df.columns:\n",
    "            pattern = re.compile(rf'^away_{feature}_\\d+$')\n",
    "            if pattern.match(colonna):\n",
    "                Test_dict_features[feature][colonna]=Test_df[colonna]\n",
    "\n",
    "    #encoding teams\n",
    "    # load the  transformer\n",
    "    teams_transf = joblib.load('transformers/teams_transformer.pkl')\n",
    "\n",
    "    Train_teams_encoded = teams_transf.transform(Train_teams)\n",
    "    Valid_teams_encoded = teams_transf.transform(Valid_teams)\n",
    "    Test_teams_encoded = teams_transf.transform(Test_teams)\n",
    "\n",
    "    #encoding labels\n",
    "    # load the  transformer\n",
    "    ordinal_encoder = joblib.load('transformers/ordinal_encoder_transformer.pkl')\n",
    "\n",
    "    Train_labels_encoded = np.squeeze(ordinal_encoder.transform(np.array(Train_labels).reshape(-1, 1)))\n",
    "    Valid_labels_encoded = np.squeeze(ordinal_encoder.transform(np.array(Valid_labels).reshape(-1, 1)))\n",
    "    Test_labels_encoded = np.squeeze(ordinal_encoder.transform(np.array(Test_labels).reshape(-1, 1)))  \n",
    "\n",
    "    #encoding numerical features\n",
    "    Train_dict_features_norm = Train_dict_features.copy()\n",
    "    Valid_dict_features_norm = Valid_dict_features.copy()\n",
    "    Test_dict_features_norm = Test_dict_features.copy()\n",
    "\n",
    "    for feature in list(Train_dict_features.keys()):\n",
    "        # load the  transformer\n",
    "        numerical_transf = joblib.load(f'transformers/numerical_{feature}_transformer.pkl')\n",
    "\n",
    "        Train_dict_features_norm[feature] = numerical_transf.transform(Train_dict_features_norm[feature])\n",
    "        Valid_dict_features_norm[feature] = numerical_transf.transform(Valid_dict_features_norm[feature])\n",
    "        Test_dict_features_norm[feature] = numerical_transf.transform(Test_dict_features_norm[feature])\n",
    "    \n",
    "    # Encoding odds\n",
    "    # load the  transformer\n",
    "    odds_transf = joblib.load('transformers/odds_transformer.pkl')\n",
    "\n",
    "    Train_odds_norm = odds_transf.transform(Train_odds)\n",
    "    Valid_odds_norm = odds_transf.transform(Valid_odds)\n",
    "    Test_odds_norm = odds_transf.transform(Test_odds)\n",
    "\n",
    "    return (Train_teams_encoded, Valid_teams_encoded, Test_teams_encoded, Train_labels_encoded, Valid_labels_encoded, Test_labels_encoded, \n",
    "            Train_dict_features_norm, Valid_dict_features_norm, Test_dict_features_norm, Train_teams, Valid_teams, Test_teams, Train_labels, Valid_labels, Test_labels, \n",
    "            Train_dict_features, Valid_dict_features, Test_dict_features, Train_df, Valid_df, Test_df, \n",
    "            Train_odds_norm, Valid_odds_norm, Test_odds_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtaining the new odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "column_types = {'1': float, 'x': float, '2': float}\n",
    "last_odds = pd.read_csv(r'Data_scraping/last_odds.csv', dtype=column_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding the new results to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leggi il file CSV\n",
    "df = pd.read_csv(r\"C:\\Users\\Hp\\Serie_A\\csv_predictions\\stagione_23_24.csv\", parse_dates=['Date'], dayfirst=True)\n",
    "df = df[df['Date'] != today_date]\n",
    "\n",
    "# Crea un DataFrame con 10 righe di zeri\n",
    "new_rows = pd.DataFrame(0, index=range(10), columns=df.columns)\n",
    "\n",
    "# # Assegna valori specifici alle colonne 'Div', 'Date', 'Time', 'HomeTeam', 'AwayTeam' per ciascuna riga\n",
    "# new_rows.loc[0, ['Div', 'Date', 'Time', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR']] = ['I1', f'{today_date}', '17:30', 'Juventus', 'Napoli',0,0,'D']\n",
    "# new_rows.loc[1, ['Div', 'Date', 'Time', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR']] = ['I1', f'{today_date}', '17:30', 'Verona', 'Lazio',0,0,'D']\n",
    "# new_rows.loc[2, ['Div', 'Date', 'Time', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR']] = ['I1', f'{today_date}', '17:30', 'Atalanta', 'Milan',0,0,'D']\n",
    "# new_rows.loc[3, ['Div', 'Date', 'Time', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR']] = ['I1', f'{today_date}', '17:30', 'Inter', 'Udinese',0,0,'D']\n",
    "# new_rows.loc[4, ['Div', 'Date', 'Time', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR']] = ['I1', f'{today_date}', '17:30', 'Frosinone', 'Torino',0,0,'D']\n",
    "# new_rows.loc[5, ['Div', 'Date', 'Time', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR']] = ['I1', f'{today_date}', '17:30', 'Monza', 'Genoa',0,0,'D']\n",
    "# new_rows.loc[6, ['Div', 'Date', 'Time', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR']] = ['I1', f'{today_date}', '17:30', 'Salernitana', 'Bologna',0,0,'D']\n",
    "# new_rows.loc[7, ['Div', 'Date', 'Time', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR']] = ['I1', f'{today_date}', '17:30', 'Roma', 'Fiorentina',0,0,'D']\n",
    "# new_rows.loc[8, ['Div', 'Date', 'Time', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR']] = ['I1', f'{today_date}', '17:30', 'Empoli', 'Lecce',0,0,'D']\n",
    "# new_rows.loc[9, ['Div', 'Date', 'Time', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR']] = ['I1', f'{today_date}', '17:30', 'Cagliari', 'Sassuolo',0,0,'D']\n",
    "\n",
    "new_rows.loc[0, ['Div', 'Date', 'Time', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR']] = ['I1', f'{today_date}', '17:30', 'Genoa', 'Juventus',0,0,'D']\n",
    "new_rows.loc[1, ['Div', 'Date', 'Time', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR']] = ['I1', f'{today_date}', '17:30', 'Lecce', 'Frosinone',0,0,'D']\n",
    "new_rows.loc[2, ['Div', 'Date', 'Time', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR']] = ['I1', f'{today_date}', '17:30', 'Napoli', 'Cagliari',0,0,'D']\n",
    "new_rows.loc[3, ['Div', 'Date', 'Time', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR']] = ['I1', f'{today_date}', '17:30', 'Torino', 'Empoli',0,0,'D']\n",
    "new_rows.loc[4, ['Div', 'Date', 'Time', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR']] = ['I1', f'{today_date}', '17:30', 'Milan', 'Monza',0,0,'D']\n",
    "new_rows.loc[5, ['Div', 'Date', 'Time', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR']] = ['I1', f'{today_date}', '17:30', 'Fiorentina', 'Verona',0,0,'D']\n",
    "new_rows.loc[6, ['Div', 'Date', 'Time', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR']] = ['I1', f'{today_date}', '17:30', 'Udinese', 'Sassuolo',0,0,'D']\n",
    "new_rows.loc[7, ['Div', 'Date', 'Time', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR']] = ['I1', f'{today_date}', '17:30', 'Bologna', 'Roma',0,0,'D']\n",
    "new_rows.loc[8, ['Div', 'Date', 'Time', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR']] = ['I1', f'{today_date}', '17:30', 'Lazio', 'Inter',0,0,'D']\n",
    "new_rows.loc[9, ['Div', 'Date', 'Time', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR']] = ['I1', f'{today_date}', '17:30', 'Atalanta', 'Salernitana',0,0,'D']\n",
    "\n",
    "#inserisco le nuove quote\n",
    "i=0\n",
    "for index, row in last_odds.iterrows():\n",
    "    win, draw, loss = row\n",
    "    new_rows.loc[i,['B365H', 'B365D', 'B365A']] = [win,draw,loss]\n",
    "    i=i+1\n",
    "\n",
    "# new_rows.loc[0,['B365H', 'B365D', 'B365A']] = [4.75, 3.25, 1.85]\n",
    "# new_rows.loc[1,['B365H', 'B365D', 'B365A']] = [2.05, 3.35, 3.6]\n",
    "# new_rows.loc[2,['B365H', 'B365D', 'B365A']] = [1.3, 5.5, 9.0]\n",
    "# new_rows.loc[3,['B365H', 'B365D', 'B365A']] = [1.55, 4.0, 6.0]\n",
    "# new_rows.loc[4,['B365H', 'B365D', 'B365A']] = [1.55, 4.25, 5.75]\n",
    "# new_rows.loc[5,['B365H', 'B365D', 'B365A']] = [1.45, 4.5, 6.5]\n",
    "# new_rows.loc[6,['B365H', 'B365D', 'B365A']] = [2.25, 3.5, 3.05]\n",
    "# new_rows.loc[7,['B365H', 'B365D', 'B365A']] = [2.35, 3.0, 3.3]\n",
    "# new_rows.loc[8,['B365H', 'B365D', 'B365A']] = [4.75, 3.7, 1.73]\n",
    "# new_rows.loc[9,['B365H', 'B365D', 'B365A']] = [1.3, 5.5, 8.75]\n",
    "\n",
    "# Aggiungi le nuove righe al DataFrame esistente\n",
    "new_csv = pd.concat([df, new_rows], ignore_index=True)\n",
    "new_csv['Date'] = pd.to_datetime(new_csv['Date'], format='%Y-%m-%d')\n",
    "\n",
    "# Salva il DataFrame aggiornato su un nuovo file CSV\n",
    "new_csv.to_csv(r\"C:\\Users\\Hp\\Serie_A\\csv_predictions\\stagione_23_24.csv\")\n",
    "\n",
    "len(new_csv['HomeTeam'].unique()), len(new_csv['AwayTeam'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: I1 (0).csv\n",
      "Reading file: I1 (1).csv\n",
      "Reading file: I1 (10).csv\n",
      "Reading file: I1 (11).csv\n",
      "Reading file: I1 (12).csv\n",
      "Reading file: I1 (13).csv\n",
      "Reading file: I1 (14).csv\n",
      "Reading file: I1 (15).csv\n",
      "Reading file: I1 (16).csv\n",
      "Reading file: I1 (17).csv\n",
      "Reading file: I1 (2).csv\n",
      "Reading file: I1 (3).csv\n",
      "Reading file: I1 (4).csv\n",
      "Reading file: I1 (5).csv\n",
      "Reading file: I1 (6).csv\n",
      "Reading file: I1 (7).csv\n",
      "Reading file: I1 (8).csv\n",
      "Reading file: I1 (9).csv\n",
      "Reading file: stagione_23_24.csv\n",
      "preprocessing finished!\n",
      "utilizzando meno features\n",
      "preprocess finished\n",
      "utilizzando meno features\n",
      "utilizzando meno features\n",
      "utilizzando meno features\n"
     ]
    }
   ],
   "source": [
    "#preprocess the data\n",
    "df_giornate = preprocess_match_days(r\"C:\\Users\\Hp\\Serie_A\\csv_predictions\")\n",
    "num_features = 'less'\n",
    "num_giornate = 4\n",
    "Statistiche_squadre_dict = preprocess_teams(dataframe = df_giornate)\n",
    "df_Serie_A = create_time_series_features(num_features, Statistiche_squadre_dict, df_giornate, num_giornate).dropna()\n",
    "\n",
    "(Train_teams_encoded, Valid_teams_encoded, Test_teams_encoded, Train_labels_encoded, Valid_labels_encoded, Test_labels_encoded, \n",
    "    Train_dict_features_norm, Valid_dict_features_norm, Test_dict_features_norm, Train_teams, Valid_teams, Test_teams, Train_labels, Valid_labels, \n",
    "    Test_labels, Train_dict_features, Valid_dict_features, Test_dict_features, Train_df, Valid_df, Test_df, \n",
    "    Train_odds_norm, Valid_odds_norm, Test_odds_norm) = preprocess_features_time_series_odds_preds(df_Serie_A, num_features, today_date)\n",
    "\n",
    "feature_input_shape = Test_dict_features_norm[list(Test_dict_features_norm.keys())[0]].shape[1]\n",
    "Train_teams_shape = Test_teams_encoded.shape[1]\n",
    "\n",
    "Dataset_train_norm, Dataset_valid_norm, Dataset_test_norm = create_fast_preprocessing_ts_odds(Train_teams_encoded, Train_dict_features_norm, Train_labels_encoded,\n",
    "                                                                                         Valid_teams_encoded, Valid_dict_features_norm,\n",
    "                                                                    Valid_labels_encoded,Test_teams_encoded, Test_dict_features_norm, Test_labels_encoded, \n",
    "                                                                    Train_odds_norm, Valid_odds_norm, Test_odds_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the model \n",
    "odds_model = tf.keras.models.load_model(r'c:\\Users\\Hp\\Serie_A\\model_experiments\\model_odds_time_series')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000231669D0F40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 286ms/step\n"
     ]
    }
   ],
   "source": [
    "## Visualizziamo un po' di risultati \n",
    "model_odds_new_pred_probs = odds_model.predict((Dataset_test_norm))\n",
    "model_odds_new_prob = model_odds_new_pred_probs.max(axis=1)\n",
    "model_odds_new_predictions = model_odds_new_pred_probs.argmax(axis=1)\n",
    "model_odds_new_compare = pd.DataFrame({\n",
    "                                'hometeam': list( Test_df['hometeam'] ),\n",
    "                                'awayteam': list( Test_df['awayteam'] ),\n",
    "                                'preds': model_odds_new_predictions, \n",
    "                                'best_pred_prob': model_odds_new_prob,\n",
    "                                })\n",
    "\n",
    "model_odds_new_compare[['model_away_prob','model_draw_prob','model_home_prob']] = model_odds_new_pred_probs\n",
    "model_odds_new_compare[['home_win_odds', 'draw_odds', 'away_win_odds']] = Test_df[['home_win_odds', 'draw_odds', 'away_win_odds']].values\n",
    "model_odds_new_compare['snai_pred'] = np.argmin(Test_df[['home_win_odds', 'draw_odds', 'away_win_odds']].fillna(0.0).to_numpy(), axis=1)\n",
    "model_odds_new_compare['snai_prob'] = np.nanmin(Test_df[['home_win_odds', 'draw_odds', 'away_win_odds']].fillna(0.0).to_numpy(), axis=1)\n",
    "\n",
    "# Assegno ai valori encoded dei valori più comprensibili per vittoria pareggio sconfitta\n",
    "conditions = [\n",
    "(model_odds_new_compare['preds'] == 2),  # Condizione per Home Win\n",
    "(model_odds_new_compare['preds'] == 0),  # Condizione per Away Win\n",
    "(model_odds_new_compare['preds'] == 1)   # Condizione per draw\n",
    "]\n",
    "conditions_snai = [\n",
    "(model_odds_new_compare['snai_pred'] == 0),  # Condizione per Home Win\n",
    "(model_odds_new_compare['snai_pred'] == 2),  # Condizione per Away Win\n",
    "(model_odds_new_compare['snai_pred'] == 1)   # Condizione per Draw\n",
    "]\n",
    "# Valori corrispondenti alle condizioni\n",
    "values = ['H', 'A', 'D']\n",
    "\n",
    "# Creazione della nuova colonna 'result' e 'points\n",
    "model_odds_new_compare['preds'] = np.select(conditions, values)\n",
    "model_odds_new_compare['snai_pred'] = np.select(conditions_snai, values)\n",
    "model_odds_new_compare['money_won'] = model_odds_new_compare['best_pred_prob']*model_odds_new_compare['snai_prob']\n",
    "\n",
    "# creo la colonna money won \n",
    "model_odds_new_compare['pred_odds'] = model_odds_new_compare.apply(lambda row: row['home_win_odds'] if row['preds'] == 'H' else (row['draw_odds'] if row['preds'] == 'D' \n",
    "                                                                                             else row['away_win_odds']), axis=1)\n",
    "# Inserisci la colonna nella nuova posizione\n",
    "insert_data = model_odds_new_compare['money_won']\n",
    "model_odds_new_compare.drop(columns=['money_won'], inplace=True)\n",
    "model_odds_new_compare.insert(5, 'money_won', insert_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stagione</th>\n",
       "      <th>hometeam</th>\n",
       "      <th>awayteam</th>\n",
       "      <th>preds</th>\n",
       "      <th>best_pred_prob</th>\n",
       "      <th>money_won</th>\n",
       "      <th>model_away_prob</th>\n",
       "      <th>model_draw_prob</th>\n",
       "      <th>model_home_prob</th>\n",
       "      <th>home_win_odds</th>\n",
       "      <th>draw_odds</th>\n",
       "      <th>away_win_odds</th>\n",
       "      <th>snai_pred</th>\n",
       "      <th>snai_prob</th>\n",
       "      <th>pred_odds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023/2024</td>\n",
       "      <td>Lecce</td>\n",
       "      <td>Frosinone</td>\n",
       "      <td>H</td>\n",
       "      <td>0.367370</td>\n",
       "      <td>0.771476</td>\n",
       "      <td>0.308650</td>\n",
       "      <td>0.323980</td>\n",
       "      <td>0.367370</td>\n",
       "      <td>2.10</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.55</td>\n",
       "      <td>H</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023/2024</td>\n",
       "      <td>Napoli</td>\n",
       "      <td>Cagliari</td>\n",
       "      <td>H</td>\n",
       "      <td>0.713256</td>\n",
       "      <td>0.927233</td>\n",
       "      <td>0.089408</td>\n",
       "      <td>0.197336</td>\n",
       "      <td>0.713256</td>\n",
       "      <td>1.30</td>\n",
       "      <td>5.50</td>\n",
       "      <td>9.00</td>\n",
       "      <td>H</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023/2024</td>\n",
       "      <td>Milan</td>\n",
       "      <td>Monza</td>\n",
       "      <td>H</td>\n",
       "      <td>0.601250</td>\n",
       "      <td>0.931938</td>\n",
       "      <td>0.155873</td>\n",
       "      <td>0.242877</td>\n",
       "      <td>0.601250</td>\n",
       "      <td>1.55</td>\n",
       "      <td>4.25</td>\n",
       "      <td>5.75</td>\n",
       "      <td>H</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023/2024</td>\n",
       "      <td>Lazio</td>\n",
       "      <td>Inter</td>\n",
       "      <td>A</td>\n",
       "      <td>0.552586</td>\n",
       "      <td>0.967025</td>\n",
       "      <td>0.552586</td>\n",
       "      <td>0.257130</td>\n",
       "      <td>0.190284</td>\n",
       "      <td>4.75</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1.75</td>\n",
       "      <td>A</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023/2024</td>\n",
       "      <td>Torino</td>\n",
       "      <td>Empoli</td>\n",
       "      <td>H</td>\n",
       "      <td>0.500757</td>\n",
       "      <td>0.801211</td>\n",
       "      <td>0.203756</td>\n",
       "      <td>0.295487</td>\n",
       "      <td>0.500757</td>\n",
       "      <td>1.60</td>\n",
       "      <td>3.90</td>\n",
       "      <td>5.75</td>\n",
       "      <td>H</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023/2024</td>\n",
       "      <td>Fiorentina</td>\n",
       "      <td>Verona</td>\n",
       "      <td>H</td>\n",
       "      <td>0.640063</td>\n",
       "      <td>0.928091</td>\n",
       "      <td>0.126136</td>\n",
       "      <td>0.233801</td>\n",
       "      <td>0.640063</td>\n",
       "      <td>1.45</td>\n",
       "      <td>4.50</td>\n",
       "      <td>6.75</td>\n",
       "      <td>H</td>\n",
       "      <td>1.45</td>\n",
       "      <td>1.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023/2024</td>\n",
       "      <td>Bologna</td>\n",
       "      <td>Roma</td>\n",
       "      <td>H</td>\n",
       "      <td>0.389764</td>\n",
       "      <td>0.935434</td>\n",
       "      <td>0.298928</td>\n",
       "      <td>0.311308</td>\n",
       "      <td>0.389764</td>\n",
       "      <td>2.40</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.25</td>\n",
       "      <td>H</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023/2024</td>\n",
       "      <td>Atalanta</td>\n",
       "      <td>Salernitana</td>\n",
       "      <td>H</td>\n",
       "      <td>0.621100</td>\n",
       "      <td>0.807430</td>\n",
       "      <td>0.125946</td>\n",
       "      <td>0.252954</td>\n",
       "      <td>0.621100</td>\n",
       "      <td>1.30</td>\n",
       "      <td>5.50</td>\n",
       "      <td>9.00</td>\n",
       "      <td>H</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023/2024</td>\n",
       "      <td>Genoa</td>\n",
       "      <td>Juventus</td>\n",
       "      <td>A</td>\n",
       "      <td>0.556978</td>\n",
       "      <td>1.002560</td>\n",
       "      <td>0.556978</td>\n",
       "      <td>0.256895</td>\n",
       "      <td>0.186127</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.30</td>\n",
       "      <td>1.80</td>\n",
       "      <td>A</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023/2024</td>\n",
       "      <td>Udinese</td>\n",
       "      <td>Sassuolo</td>\n",
       "      <td>H</td>\n",
       "      <td>0.400832</td>\n",
       "      <td>0.901871</td>\n",
       "      <td>0.282521</td>\n",
       "      <td>0.316648</td>\n",
       "      <td>0.400832</td>\n",
       "      <td>2.25</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.05</td>\n",
       "      <td>H</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    stagione    hometeam     awayteam preds  best_pred_prob  money_won  \\\n",
       "0  2023/2024       Lecce    Frosinone     H        0.367370   0.771476   \n",
       "1  2023/2024      Napoli     Cagliari     H        0.713256   0.927233   \n",
       "2  2023/2024       Milan        Monza     H        0.601250   0.931938   \n",
       "3  2023/2024       Lazio        Inter     A        0.552586   0.967025   \n",
       "4  2023/2024      Torino       Empoli     H        0.500757   0.801211   \n",
       "5  2023/2024  Fiorentina       Verona     H        0.640063   0.928091   \n",
       "6  2023/2024     Bologna         Roma     H        0.389764   0.935434   \n",
       "7  2023/2024    Atalanta  Salernitana     H        0.621100   0.807430   \n",
       "8  2023/2024       Genoa     Juventus     A        0.556978   1.002560   \n",
       "9  2023/2024     Udinese     Sassuolo     H        0.400832   0.901871   \n",
       "\n",
       "   model_away_prob  model_draw_prob  model_home_prob  home_win_odds  \\\n",
       "0         0.308650         0.323980         0.367370           2.10   \n",
       "1         0.089408         0.197336         0.713256           1.30   \n",
       "2         0.155873         0.242877         0.601250           1.55   \n",
       "3         0.552586         0.257130         0.190284           4.75   \n",
       "4         0.203756         0.295487         0.500757           1.60   \n",
       "5         0.126136         0.233801         0.640063           1.45   \n",
       "6         0.298928         0.311308         0.389764           2.40   \n",
       "7         0.125946         0.252954         0.621100           1.30   \n",
       "8         0.556978         0.256895         0.186127           5.00   \n",
       "9         0.282521         0.316648         0.400832           2.25   \n",
       "\n",
       "   draw_odds  away_win_odds snai_pred  snai_prob  pred_odds  \n",
       "0       3.30           3.55         H       2.10       2.10  \n",
       "1       5.50           9.00         H       1.30       1.30  \n",
       "2       4.25           5.75         H       1.55       1.55  \n",
       "3       3.70           1.75         A       1.75       1.75  \n",
       "4       3.90           5.75         H       1.60       1.60  \n",
       "5       4.50           6.75         H       1.45       1.45  \n",
       "6       3.00           3.25         H       2.40       2.40  \n",
       "7       5.50           9.00         H       1.30       1.30  \n",
       "8       3.30           1.80         A       1.80       1.80  \n",
       "9       3.50           3.05         H       2.25       2.25  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_odds_new_compare"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
